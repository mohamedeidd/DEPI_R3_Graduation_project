# DEPI_R3_Graduation_project
## **📌 Project Overview**
**👕 Multi-Modal Clothing Classifier**

Fashion styles can be subjective, but by combining visual features from clothing images with textual features like product descriptions, we can build a multi-modal model that classifies clothing styles more accurately than single-input models.

# **🎯 Objectives**

- 🖼️ Use CNNs for image features.

- 📝 Use Transformers for text features.

- 🔗 Combine both to create a multi-modal classifier.

- 📈 Evaluate model performance on fashion datasets.

# **🛠️ Tech Stack**

**Language**: Python

**Deep Learning**: TensorFlow 

**Image Processing** : OpenCV, PIL

**Text Processing** : NLTK, HuggingFace Transformers

**Visualization** : Matplotlib, Seaborn

**Data Handling** : NumPy, Pandas

**Machine Learning** : sci-kit learn

📂 Project Structure
├── data/                # Dataset (images + text)
├── notebooks/           # Jupyter notebooks for experiments
├── models/              # Saved trained models
└── README.md            # Project documentation

# **📊 Expected Results**

Better accuracy using multi-modal inputs rather than single-input models.

Visualizations like training curves, confusion matrix, and sample predictions.

# **👥 Team Members**

Mohamed Eid

[Team Member 2 Name]

[Team Member 3 Name]

[Team Member 4 Name]

Instructor: *Aya Hesham*


# **✨ Acknowledgments**

Special thanks to *Aya Hesham* for supervision and guidance throughout the whole learning process.
